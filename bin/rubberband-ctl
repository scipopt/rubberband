#!/usr/bin/env python

import click
from elasticsearch import Elasticsearch
from elasticsearch_dsl import Q, Search
from elasticsearch_dsl.connections import connections
import glob
import os.path
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

from rubberband.models import Result, File, TestSet
from rubberband.utils import ResultClient
from rubberband.version import __version__
from rubberband.constants import ELASTICSEARCH_INDEX
from rubberband.boilerplate import make_app

CONTEXT_SETTINGS = dict(help_option_names=['-h', '--help'])
APP_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
PACKAGE_ROOT = os.path.join(APP_ROOT, "rubberband")

make_app(PACKAGE_ROOT)

@click.group(context_settings=CONTEXT_SETTINGS)
@click.version_option(version=__version__)
def main():
    pass


@main.command()
def delete_index():
    '''
    Delete the current index.
    '''
    conn = connections.get_connection()
    conn.indices.delete(index=ELASTICSEARCH_INDEX)


@main.command()
def create_index():
    '''
    Create an index with the the required mappings (Result, File, TestSet).
    '''
    Result.init()
    File.init()
    TestSet.init()


@main.command()
def populate_index():
    '''
    Seed Elasticsearch with results from the tests/data directory.
    '''
    filepath = os.path.join(APP_ROOT, "tests", "data")
    out_files = glob.glob(os.path.join(filepath, "*.out"))
    set_files = glob.glob(os.path.join(filepath, "*.set"))
    err_files = glob.glob(os.path.join(filepath, "*.err"))
    meta_files = glob.glob(os.path.join(filepath, "*.meta"))
    solu_files = glob.glob(os.path.join(filepath, "*.solu"))

    count = 0
    for f in out_files:
        paths = [f]
        # remove the .out
        base = f[:-4]
        try:
            solu_file = os.path.join(APP_ROOT, "tests", "data", base.split(".")[1] + ".solu")
        except:
            solu_file = ""
        if base + ".set" in set_files:
            paths.append(base + ".set")
        if base + ".err" in err_files:
            paths.append(base + ".err")
        if base + ".meta" in meta_files:
            paths.append(base + ".meta")
        if solu_file in solu_files:
            paths.append(solu_file)
        c = ResultClient(user="debug")

        expdate = datetime.today()
        if count < 2:
            expdate = expdate + timedelta(days=2)
        elif 2 <= count and count < 5:
            expdate = expdate - timedelta(days=2)
        elif 5 <= count and count < 8:
            expdate = None
        c.process_files(paths, remove=False, expirationdate=expdate)
        count = count+1


@main.command()
def update_db():
    '''
    Update old datastructures to new ones.
    '''
    ts = TestSet.search()
    ts = ts.query("bool", filter=[
        Q("match", mode="debug"),
        Q("match", run_initiator="adm_timo")])
    for t in ts.scan():
        # add expirationdate to debugruns that have none
        if t.expirationdate is None and t.mode == "debug" and t.run_initiator == "adm_timo":
            t.expirationdate = t.index_timestamp + relativedelta(months=1)
            print(t)
            #t.save()

        # # clean up a misunderstanding
        # if t.opt_flag not in ["spx", "spx1", "spx2", "cpx"]:
        #     if t.lp_solver == "CPLEX":
        #         t.opt_flag = "cpx"
        #     elif t.lp_solver == "SoPlex":
        #         t.opt_flag = "spx"

        # save the original upload timestamp
        # if getattr(t, "upload_timestamp", None) is None:
        #     t.upload_timestamp = t.index_timestamp
        #     t.uploader = t.run_initiator

        # continue
        # perform updates on the children
        # t.load_children()
        # for i in t.children.to_dict().values():
        #     # update the weird ipet statuses
        #     if i.Status == "solved_not_verified":
        #         i.Status = "solved not verified"
        #         i.save()


@main.command()
def delete_expired_records():
    '''
    Delete TestSets whose expirationdate lies in the past.
    If a TestSet does have an expirationdate set, then it won't get deleted here.
    This should be run regularly (nightly, weekly)
    '''
    t = TestSet.search()
    t = t.filter('range', **{'expirationdate':{'lte':'now'}})
    t = t.query("bool", filter=[
        Q("match", mode="debug"),
        Q("match", run_initiator="adm_timo")])
    for tr in t.scan():
        print("delete testset", tr.expirationdate, tr.mode, tr.index_timestamp, tr.run_initiator)
        tr.delete_all_associations()
        tr.delete()


@main.command()
def show_testsets():
    ts = TestSet.search()
    x = ts.query("bool", filter=[
        Q("match", mode="debug"),
        Q("match", run_initiator="debug")])
    for r in x:
        print(r)


@main.command()
def load_children():
    ts_id = "AWzcqvmjmbWLq0fbeaAd"
    ts = TestSet.get(id=ts_id)
    print(ts.id)

    ts_id = ts.id
    s = Result.search().query('has_parent', type='testset', query=Q('term', id=ts_id))
    total = s.count()
    s = s[0:total]
    res = s.execute()
    print(res)
    for r in res:
        print(r)
        print(r.meta.parent)


if __name__ == "__main__":
    main()
